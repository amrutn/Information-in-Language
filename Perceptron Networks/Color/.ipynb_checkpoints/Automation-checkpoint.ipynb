{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "import numpy as np\n",
    "import json\n",
    "import Language_Data_Scraper as LD\n",
    "sys.path.insert(0, '..')\n",
    "from net_framework import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1], [2], [3], [4], [5], [6], [3, 3], [7], [8], [4, 4], [9], [3, 3, 3], [10], [5, 5], [3, 4, 3], [11], [3, 5, 3], [12], [6, 6], [4, 4, 4], [13], [4, 5, 4], [14], [7, 7], [4, 6, 4], [15], [5, 5, 5], [16], [8, 8], [5, 6, 5], [17], [5, 7, 5], [18], [9, 9], [6, 6, 6], [19], [6, 7, 6], [20], [10, 10], [6, 8, 6], [21], [7, 7, 7], [22], [11, 11], [7, 8, 7], [23], [7, 9, 7], [24], [12, 12], [8, 8, 8]]\n"
     ]
    }
   ],
   "source": [
    "node_num = range(1,25)\n",
    "layer_num = range(1,4)\n",
    "\n",
    "\n",
    "shape_collection = []\n",
    "for node in node_num:\n",
    "    if node < 3:\n",
    "        shape_collection.append([node])\n",
    "\n",
    "def trickle(arr, iteration_left, check):\n",
    "    if iteration_left == 0:\n",
    "        global shape_collection\n",
    "        #running the int fxn to make sure we don't have floats\n",
    "        mp = map(int, arr)\n",
    "        x = list(mp)\n",
    "        if check == sum(x):\n",
    "            shape_collection.append(x)\n",
    "    else:\n",
    "        new_arr = [0]+ arr + [0]\n",
    "        #recursively expanding the list symmetrically\n",
    "        while new_arr[0] < new_arr[1]-2 and new_arr[-1] < new_arr[-2]-2:\n",
    "            new_arr[0] += 1\n",
    "            new_arr[1] -= 1\n",
    "            new_arr[-1] += 1\n",
    "            new_arr[-2] -= 1\n",
    "        trickle(new_arr, iteration_left - 1, check)\n",
    "\n",
    "for node in node_num:\n",
    "    for layer in layer_num:\n",
    "        if node//layer < 3:\n",
    "            continue\n",
    "        if layer%2 == 0:\n",
    "            trickle([node/2, node/2], (layer-2)/2, node)\n",
    "        else:\n",
    "            trickle([node], (layer-1)/2, node)      \n",
    "\n",
    "print(shape_collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainingHelper:\n",
    "\n",
    "    def __init__(self, language_number, network_hidden_sizes, num_iters, test_train_split_percentage):\n",
    "        self.num_iters = num_iters\n",
    "        self.input_size = 3\n",
    "        self.rate = 0.001\n",
    "        self.language = LD.LanguageData(language_number)\n",
    "        self.colors_num = self.language.colors_num()\n",
    "        self.test_train_split_percentage = test_train_split_percentage\n",
    "        self.network_shapes = [(self.input_size, s, self.colors_num) for s in network_hidden_sizes]\n",
    "\n",
    "    def shuffle(self):\n",
    "        lab_train, lab_test, chip_train, chip_test = train_test_split(self.language.lab_norm, self.language.chip_norm(), test_size = self.test_train_split_percentage,\n",
    "        shuffle = True)\n",
    "        input_train = torch.FloatTensor(lab_train)\n",
    "        output_train = torch.FloatTensor(chip_train)\n",
    "        input_test= torch.FloatTensor(lab_test)\n",
    "        output_test = torch.FloatTensor(chip_test)\n",
    "        return input_train, output_train, input_test, output_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train:\n",
    "\n",
    "    def __init__(self, num_average, network_hidden_sizes, num_iters, num_strikes, test_train_split_percentage, language_number):\n",
    "        #Array of losses over training period for each network\n",
    "        self.num_average = num_average\n",
    "        self.num_strikes = num_strikes\n",
    "        self.language_number = language_number\n",
    "        self.output_file = {}\n",
    "        for n in node_num:\n",
    "            self.output_file[n] = {}\n",
    "        self.th = TrainingHelper(language_number, network_hidden_sizes, num_iters, test_train_split_percentage)\n",
    "\n",
    "    def run(self):\n",
    "        for net_num, shape in enumerate(self.th.network_shapes):\n",
    "            print(\"Training: \",shape)\n",
    "            net_error_arr = []\n",
    "            for j in range(self.num_average):\n",
    "                print('Run ' + str(j+1))\n",
    "                NN = Neural_Network(inputSize = shape[0], outputSize = shape[2],\n",
    "                                    hiddenSize = shape[1] , learning_rate = self.th.rate)\n",
    "                error_arr = []\n",
    "                prev_error = 0\n",
    "                strike = 0\n",
    "\n",
    "                input_train, output_train, input_test, output_test = self.th.shuffle()\n",
    "\n",
    "                for i in range(self.th.num_iters):  \n",
    "                    NN.train(input_train, output_train)\n",
    "                    validation_error = NN.l1error(output_test, NN(input_test))\n",
    "                    #Printing error\n",
    "                    if i == 0: \n",
    "                        dh = display(\"#\" + str(i) + \" Validation Error: \" + str(validation_error), display_id=True)\n",
    "                    else:\n",
    "                        dh.update(\"#\" + str(i) + \" Validation Error: \" + str(validation_error))\n",
    "                    \n",
    "                    #zero small error change\n",
    "                    if i == 0:\n",
    "                        strike = 0\n",
    "                    #adding error to array\n",
    "                    error_arr.append(validation_error)\n",
    "                    #waiting for number 'too small' decreases or increases in validation error before ending training\n",
    "                    if (prev_error < validation_error) and i > 100:\n",
    "                        if strike > self.num_strikes:\n",
    "                            print(\"Complete at iteration \", i, \"\\nFinal error: \", np.min(error_arr), \"\\n\")\n",
    "                            break\n",
    "                        else:\n",
    "                            strike += 1\n",
    "                    prev_error = validation_error\n",
    "                net_error_arr.append(np.min(error_arr))\n",
    "            self.output_file[sum(shape[1])][len(shape[1])] = [np.mean(net_error_arr), np.std(net_error_arr)]\n",
    "\n",
    "    def save_file(self):\n",
    "        self.run()\n",
    "        with open('validation_errors_{0}.json'.format(self.language_number), 'w') as f:\n",
    "            json.dump(self.output_file, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/ULAB 2020-21/Information-in-Language/Perceptron Networks/Color/Language_Data_Scraper.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-L'] = (cnum_data['L*'] - cnum_data['L*'].mean())/(cnum_data['L*'] - cnum_data['L*'].mean()).std() * 1/2\n",
      "/home/jovyan/ULAB 2020-21/Information-in-Language/Perceptron Networks/Color/Language_Data_Scraper.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-a'] = (cnum_data['a*'] - cnum_data['a*'].mean())/(cnum_data['a*'] - cnum_data['a*'].mean()).std() * 1/2\n",
      "/home/jovyan/ULAB 2020-21/Information-in-Language/Perceptron Networks/Color/Language_Data_Scraper.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  locations['Normalized-b'] = (cnum_data['b*'] - cnum_data['b*'].mean())/(cnum_data['b*'] - cnum_data['b*'].mean()).std() * 1/2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [1], 9)\n",
      "Run 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Validation Error: 0.09877661615610123'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [2], 9)\n",
      "Run 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#99 Validation Error: 0.061713941395282745'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training:  (3, [3], 9)\n",
      "Run 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'#93 Validation Error: 0.06257818639278412'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "language_1 = Train(1, shape_collection, 100, 5, 0.2, 1)\n",
    "language_1.save_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('validation_errors.json') as f:\n",
    "    output_file=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for size in node_num:\n",
    "    out_dict_for_size = output_file[str(size)]\n",
    "    vals = list(out_dict_for_size.values())\n",
    "    vals = np.array(vals)\n",
    "    vals = vals[:,0]\n",
    "    errors.append(np.min(vals))\n",
    "errors = np.array(errors)\n",
    "\n",
    "thresholds = np.arange(.001, 1, .001)\n",
    "\n",
    "min_sizes = []\n",
    "for threshold in thresholds:\n",
    "    idx = 0\n",
    "    for err in errors:\n",
    "        if err <= threshold:\n",
    "            break\n",
    "        idx += 1\n",
    "    if idx < len(node_num):\n",
    "        min_sizes.append(node_num[idx])\n",
    "    else:\n",
    "        min_sizes.append(max(node_num))\n",
    "        \n",
    "plt.title('Threshold Plot for Language {0}'.format(1))\n",
    "plt.plot(thresholds, min_sizes)\n",
    "plt.xlabel('Error Treshold Value')\n",
    "plt.ylabel('Minimum Network Size')\n",
    "plt.xlim(0,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
